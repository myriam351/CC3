---
title: "CC3 Écogénomique - Myriam FERBLANTIER - N°22000007 - Article : Illumina MiSeq 16S amplicon sequence analysis of bovine respiratory disease associated bacteria in lung and mediastinal lymph node tissue"
output:
  github_document:
    toc: true
    toc_depth: 2
---
 
 

```{r}
library(Rcpp)
library(dada2)
```
### Commentaire : Recharge des packages dada2 et Rcpp.



```{r}
path <- "~/CC2/donnees" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
### Commentaire : Retraçage du fichier de données. Les fichiers ont été mis dans le dossier données. Ensuite,on a mis ces derniers dans l'objet "path".



```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_1.fastq.gz and SAMPLENAME_2.fastq.gz
fnFs <- sort(list.files(path, pattern="1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="2.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_2.fastq.gz
sample.names <- sapply(strsplit(basename(fnFs), "_"), '[', 1)
```
### Commentaire: Nous avons obtenus les listes correspondantes des fichiers fastq pour les amorces Foward et Reverse. On a filtré les read 1 et 2 (qui correspond à 1.fastq.gz et 2.fastq.gz) et ils ont été mis dans des objets, dont fnFs (pour les Foward) et fnRs (pour les Reverse). Ensuite, l'objet fnFs pour les amorce Foward filtrées ont été mis dans l'objet sample.names.



## Inspect read quality profiles
```{r}
plotQualityProfile(fnFs[1:2])
```



```{r}
plotQualityProfile(fnRs[1:2])
```
###Commentaire: En utilisant la fonction plotQualityProfile() on peut observer sous forme de graphique le contrôle qualité des amorces Foward et Reverse. En effet, on peut avoir le profil qualité des amorces utilisées.On peut voir qu'en abscisse on a les cycles et en ordonnée on a les scores de qualités. La ligne orange correspond à la longueur de chaque read et la ligne verte correspond au score de qualité moyen. Ici les read 1 et 2 ont été sélectionné pour observer leur score de qualité. En peut voir en premier lieu, les amorces Foward et les Reverse en second temps, pour les read 1 et 2. Pour les deux premiers graphiques, on peut voir que les scores de qualités diminue progressivement pour les amorce Foward. Les scores de qualités diminuent (<Q30) jusqu'à arrivé au 250ème cycles. Cette diminution du score de qualité est plus amplifié au niveau des 2 autres graphiques (en dessous) pour les amorces Reverse.



## Filter and trim
```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_1.filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_2.filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```
### Commentaire: Attributions des fichiers filtrés aux objets filtFs (pour les Foward) et filtRs (pour les Reverse). Ensuite, L'objet samples.names a été mis dans un autre objet (=renommé).



```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250,200), trimLeft = c(21,21),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```
### Commentaire : Nous avons utilisé des paramètres de filtrage pour filtrer nos données (soit truncLen=c(250,200), trimLeft = c(21,21),maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE). La fonction qui a permis le filtrage est la fonction filterAndtrim(). Par exemple: Le paramètre maxEE définit le nombre maximum d’“erreurs attendues” autorisées dans une lecture. La fonction maxN=0 permet d'enlever toutes les bases où il y aura un N (c'est-à-dire un A,T,C et G) dans un read. rm.phix permet de donner un profil d'erreur à chaque séquençage.

### Commentaire : En utilisant la fonction truncLen=c(250,200), on a sélectionné les amorces tronquées et on les a filtrés en précisent les zones (soit 250 à 200).



## Learn the Error Rates
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```



```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
### Commentaire : Ici on apprend via la fonction learnErrors() les taux d’erreurs à partir des amorces filtrées. Ces taux d'erreurs vont permettrent de créer des modèles d'erreurs, pour pouvoir corriger nos read. On a mis ces modèles d'erreurs dans des objets, tels que errF (pour les Foward) et errR (pour les Reverse). Pour les amorces Foward on a utilisé ****** échantillons et pour les Reverse on a utilisé ********  échantillons.



```{r}
plotErrors(errF, nominalQ=TRUE)
```
### Commentaire : On peut Visualiser des taux d’erreurs estimés, via la fonction plotErrors().



```{r}
plotErrors(errR, nominalQ=TRUE)
```
### Commentaire : On peut Visualiser des taux d’erreurs estimés, via la fonction plotErrors().



## Sample Inference
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
### Commentaire : Visualisation des taux d’erreurs pour les Forward.



```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
### Commentaire : Visualisation des taux d’erreurs pour les Reverse.



```{r}
dadaFs[[1]]
```
### Commentaire : Ici on a effectué une inspection des données, avec 1016 variantes de séquences à partir des séquences uniques de 39978 dans le premier échantillon.



```{r}
dadaFs[[3]]
```
### Commentaire : On a fait la même chose que précédemment, mais avec l’échantillon 3. On a effectué une inspection des données, avec 1170 variantes de séquences à partir des séquences uniques de 49703 dans le premier échantillon.



## Merge paired reads
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
```
### Commentaire : Fusion des lectures d’amorces Forward et Reverse. Un alignement est effectué au préalable. Par exemple, pour le premier, 115473 paires de lectures (dans 4595 paires uniques) ont été fusionnées avec succès à partir de 140326 (dans 21160 paires) entrées.


```{r}
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```



## Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
### Commentaire :Ici la fonction makeSequenceTable () permet de construire une table de séquences (analogue à une table OTU) à partir de la liste d'échantillons fournie.



```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
### Commentaire : Construction d’une table de variantes de séquences d’amplicon de 1 117 389.



## Revome chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
```
### Commentaire : On a identifié des séquences chimériques, en utilisant la fonction removeBimeraDenovo(). On a pu identifier 15 867 de chimère sur 17 389 de séquences.


```{r}
dim(seqtab.nochim)
```
### Commentaire : la fonction dim() permet de définir la dimension de objet.


```{r}
sum(seqtab.nochim)/sum(seqtab)
```



```{r}
1-sum(seqtab.nochim)/sum(seqtab)
```
### Commentaire : Il y a 2.2 % de séquence chimérique dans notre séquence unique.



## Track reads through the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
### Commentaire : Vérification de tout ce qu’on a fait depuis le début. Par exemple: on peut voir qu’on a conservé la majorité de nos lectures brutes.



## Assign taxonomy
```{bash}
wget https://zenodo.org/record/3986799/files/silva_nr99_v138_train_set.fa.gz
```
### Commentaire : On a importé les données Silva.

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/CC2/silva_nr99_v138_train_set.fa.gz", multithread = TRUE)
```
### Commentaire : La fonction assignTaxonomy() met en œuvre l'algorithme du RDP Naive Bayesian Classifier.



```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```
### Commentaire : On a effectué l’assignement taxonomique en utilisant les données SILVA. Ensuite, on a examiné les affectations taxonomiques. Par exemple, on peut voir les différentes phyla, les classes, les ordres, les familles, les genres et les espèces.



```{r}
save.image(file = "02_stat-analysiscc2-with-DADA2_FinalENV")
```
### Commentaire : La fonction save.image () permet que les objets du fichier 02_stat-analysiscc2 soient sauvegardés. On va ensuite charger ce fichier de donnée dans un autre fichier 03_stat-analysiscc2 en utilisant la fonction load() par la suite.
